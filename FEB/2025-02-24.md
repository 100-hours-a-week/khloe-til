# TIL Template

## 날짜: 2025-02-24

### 새로 배운 내용
#### 주제 : 딥러닝 기초 
**인공 신경망(Artificial Neural Network,ANN 또는 NN)** 이란 ? 
머신 러닝과 인지과학에서 사용되어 패턴 인식과 문제 해결 능력을 갖추게 하는, 뇌의 뉴런 넷웍을 모방한 알고리즘이며 입력층, 은닉층, 출력층으로 구성되어 있습니다.
인간이 일일이 개입하지 않아도 자동적으로 컴퓨터가 지능적인 결정을 내리는 데 도움이 되기 때문에 사용합니다.
- **순전파(feed forward)** 란 입력 데이터를 통해 네트워크가 예측하는 값을 생성하는 과정입니다. 즉, 데이터가 각 순서의 층을 순차적으로 전달되는 과정을 나타냅니다.
    단, 이 과정에서는 오차를 계산하지는 않습니다.
- **역전파(Backpropagation)** 란? 계산된 손실 값을 기반으로, 손실을 줄이기 위해 각 가중치에 대한 기울기(gradient)를 계산하는 알고리즘입니다. 이 과정은 출력층에서 시작하여 역방향으로 진행되며, 각 층의 가중치에 대한 그레디언트를 계산합니다.
  ✨ 실제 가중치 업데이트는 역전파가 아닌, 옵티마이저가 하는 일 입니다.
- 옵티마이저의 가장 기본은 경사 하강법입니다. 그 외에도 적응형 옵티마이저(동적으로 학습률을 조정하여 학습 효율 up), 모멘텀 옵티마이저(기울기 벡터의 지수 이동 평균 사용)
    - Adam : 1,2차 모멘텀을 동시에 추정하여 학습을 가속화 하고 안정화하는 딥러닝 최적화 알고리즘 (학습 과정에서 각 파라미터의 학습률을 자동 조정)
    - 
**✅ 전체 과정**
1. 피드포워드
2. 손실 함수계산
3. 역전파
4. 옵티마이저를 통한 가중치 업데이트

- **FCNN(Fully Connected Neural Network)** 은 모든 뉴런이 이전 층의 뉴런들과 완전히 연결되는 구조입니다.
  모든 FCNN은 ANN이지만, 모든 ANN은 FCNN이 아닙니다. 
  - `nn.CrossEntropyLoss()` : 다중 클래스 분류를 위한 손실 함수입니다. 이 함수는 주로 softMax와 함계 사용되며, 확률 값이 1에 가까울수록 손실이 0에 수렴합니다.
- **모델 훈련** 
    1) num_epochs만큼 반복문 세팅
    2) 학습 모드로 설정
       1) train_loader 데이터셋에서 입력과 레이블을 가져와서 반복문 세팅
       2) 그래디언트 0으로 초기화
       3) 모델에 입력 데이터를 전달하여 예측값 도출
       4) 예측값과 실제 값 간의 손실을 계산
       5) 손실에 대한 그래디언트 계산
       6) 계산된 그래디언트 사용하여 모델의 파라미터인 가중치 업데이트
  
- **모델 평가** 
  1) 평가 모드로 설정
  2) 그래디언트를 계산하지 않도록 설정 -> 평가시에는 가중치 업데이트가 필요 없음
     1) test_loader에서 입력과 레이블을 가져와서 반복문 세팅
     2) 모델에 입력 데이터를 전달하여 예측값 도출
     3) 가장 높은 값의 인덱스를 예측된 클래스로 선택
     4) (처리된 데이터 갯수와 맞은 갯수 체크)
  3) 정확도 계산 후 출력
   
손실 함수는 해결하고자 하는 문제 유형에 따라 서로 다른 형태로 사용됩니다.
1) 회귀 문제
    a) 평균 제곱 오차 (MSE, Mean Squared Error) :  예측 값과 실제 값의 차이를 제곱한 후 평균을 구하는 손실 함수 - 이상치를 강조하고 싶을 때
    b) 평균 절대 오차: 예측 값과 실제 값 차이의 절댓값을 평균 내는 손실 함수 - 전반적인 평균 오차를 평가할 때
2) 분류 문제
    a) 크로스 엔트로피 손실(Cross-Entropy Loss): 확률 분포 간 차이 측정, 예측 확률과 실제 정답 간의 차이를 최소화하는 손실 함수 - 분류 문제에서 확률을 모델링하는 베르누이 분포를 이용한다.
    b) 힌지 손실 : 서포트 벡터 머신에서 사용되는 손실 함수- 정답과 예측 값 사이의 마진을 기반으로 손실 계산
- **CNN** : 여러 개의 Convolutional Layer, Pooling Layer, Fully Conneted Layer들로 구성된 신경망 - _이미지_ 공간 정보를 유지하며 학습할 수 있는 모델 

- **풀링 계층** : CNN에서 입력 특징 맵의 공간 크기를 줄여 계산량을 감소시키고, 중요한 특징을 추출하며, 과적합 방지하는 역할을 하는 레이어(불필요한 데이터는 걸러내기 때문) 

- **평탄화 계층** : 다차원 배열 형태의 입력 데이터를 1차원 배열로 변환하여, 주로 Fully Connected Layer(Dense Layer)에 입력으로 사용할 수 있도록 하는 신경망 레이어 -CNN에서 주로 사용 
  * CNN 모델에서 샘플은 하나의 이미지이고, 여러 샘플이 모여 Batch를 이룸.
  

### 오늘의 도전 과제와 해결 방법
- 교재- 역전파부터 예제 다시 돌려보기

### 오늘의 회고
- 일주일이 지날 수록 알고 있는 것이 많아져서 내용이 조금 심화되어도 재미있게 공부할 수 있는 것 같은 느낌이 든다. 단순히 함수를 쓰는 것이 아니라 원리가 어떤지 알고, 지금처럼 열심히 복습해야겠다.
- API 서버 열어서 작업하는 부분은 꼭 다시 해봐야겠다.
- 시간 날 때 틈틈히 실용적인 코드 작업을 해야겠다.
  

### 참고 자료 및 링크
- [Function Composition](https://en.wikipedia.org/wiki/Function_composition)
- [Convolution](https://en.wikipedia.org/wiki/Convolution)

### 참고 내용
- **그래디언트란** 함수의 기울기로, 특정 변수에 대한 손실 함수의 변화 정도를 나타내는 값입니다. 손실을 최소화하기 위해 가중치를 조정할 방향과 크기를 결정하는 데 사용합니다.
- **회귀**는 주어진 데이터를 바탕으로 미래의 값을 예측하거나, 두 변수 간의 관계를 이해하기 위한 방법입니다.
- **체인룰**은 여러개의 함수가 연결된 경우, 최종 결과의 변화율을 단계적으로 계산하는 방법입니다.(like 도미노 효과) 
- **에지** 란 이미지에서 픽셀 값이 급격하게 변하는 경계를 의미합니다.