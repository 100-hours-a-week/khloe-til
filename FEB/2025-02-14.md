# TIL Template

## 날짜: 2025-02-14

### 스크럼
- CLI 프로그래밍 과제 회고 의견 나누기

### 새로 배운 내용
#### 주제 : 시각화 Deepp Dive 
- SciPy를 활용한 통계 분석이 데이터 해석에 어떤 도움을 주나요?
  
### **✅ 단순한 평균만으로 정확한 데이터 해석이 가능할까 ?**

- 같은 평균이라도 **데이터의 변동성(분산, 표준편차)을 고려해야 정확한 해석이 가능합니다**.
- SciPy의 stats.describe() 함수를 사용하면 데이터의 왜도(skewness), 첨도(kurtosis) 등을 분석하여 평균이 왜곡된 것인지도 파악 가능합니다.

### ✅ "차이가 있다" vs. "유의미한 차이가 있다"는 완전히 다르다
📌 SciPy의 ttest_ind()(독립표본 t-검정)
t-검정을 수행하여 차이가 "우연"이 아니라 "실제 유의미한 차이"인지 확인해야 합니다.
- `p-value < 0.05`이면 → **광고 A와 B는 통계적으로 유의미한 차이가 있다고 결론**
- `p-value > 0.05`이면 → **차이가 있지만, "운이 좋아서 발생한 차이"일 수도 있음 (즉, 신뢰할 수 없음)**

### ✅ "정규성 가정을 반박 " 
📌 **SciPy의 `shapiro()`(Shapiro-Wilk Test)와 `normaltest()`(D’Agostino’s K-squared Test)로 정규성 검정**

- **`shapiro()` 귀무가설:‘ 데이터는 정규분포를 따른다‘로 정규성 검정 (소규모 데이터:n ≤ 5000일 때)**
- **`normaltest()` 귀무가설:‘ 데이터는 정규분포를 따른다‘로 정규성 검정(대규모 데이터:n > 5000일 때)**
  - `p < 0.05` → **데이터가 정규 분포를 따르지 않음!** (일반적인 t-검정을 하면 안 됨)
  - `p > 0.05` → **정규 분포를 따름 (t-검정 가능)**


### **🔭 결론 !** SciPy를 활용한 기본 통계 분석이 데이터 해석에 어떤 도움을 주나요?
**단순한 비교, 겉핥기 해석을 넘어서 우연성을 넘은 의미있는 차이인지 검증하여 데이터 해석의 신뢰성을 높이고, 정확하게 해석하는 데 유용합니다.**

### 오늘의 도전 과제와 해결 방법
- 팀원들의 Deep Dive에 대해 혼자서 더 보고 공부해보기

### 오늘의 회고
- 확실히 지난 주 보다 꼬리질문을 염두해 두고 준비를 하니 양질의 내용이 나온 것 같다.
- 다른 팀원이 질문을 해주어서 해당 부분을 찾아보는 기회가 되었고 뿌듯했다.
  - 
- 다른 사람들이 내가 준비한 글을 보고 도움이 되면 좋겠다.


### 참고 내용
- 왜도 : 데이터의 분포가 대칭적인지, 한쪽으로 치우쳐 있는지 나타내는 지표이며 정규 분포는 0에 가까움 
  - 양수이면 오른쪽(long right tail), 음수이면 왼쪽(long left tail)로 치우침
- 첨도 : 분포의 꼬리(극단값,outiler))정도를 나타내는 지표 -정규 분포는 3(Scipy에서는 기준이 0)
  - 3보다 크면 뾰족한 분포, 3보다 작으면 완만한 분포
- 비모수방법 : 데이터의 분포를 가정하지 않고 분석하는 방법 ↔ 모수방법:데이터가 특정한 분포(예: 정규 분포)를 따른다고 가정하고 분석하는 방법.
    - **정규분포를 따르지 않을 때**
    - **샘플 크기가 너무 작을 때(30 미만)**
    - **극단값이 많아 평균이 왜곡될 가능성이 있을 때**

